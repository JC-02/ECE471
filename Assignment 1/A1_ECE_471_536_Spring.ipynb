{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0nrIg51CXFF"
      },
      "source": [
        "# **ECE 471/536: Computer Vision**\n",
        "## Assignment 1: Math Preliminaries and Programming Introduction\n",
        "\n",
        "\n",
        "> Student: First Last, V00000000\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srHd9KhbFHcU"
      },
      "source": [
        "## **1. Instructions:** follow the intructions provided on a sequential manner.\n",
        "### 1.0 **Identification**\n",
        "Please enter your name and V number on the text code above.\n",
        "\n",
        "### 1.1 **Submission package**\n",
        "Your final submission package must be submitted using the [BrightSpace](https://https://bright.uvic.ca/d2l/home)  platform. You will find this assignment's specific page under **Course Tools > Assignments**. Your submission consists of:\n",
        "\n",
        "1.   *.ipynb* file: your modified version of this Google Colab template. Place your complete assignment solution/information in this version.  \n",
        "2.   *.pdf* file: a document containing a writeup with the answers to mathematical questions.\n",
        "\n",
        "### 1.2 **Coding considerations**\n",
        "* In previous years we asked students to complete assignments offline by installing either MATLAB or a Python environment in their computers. In order to standardize the submissions and guarantee that everyone has access to the same Python environment, all assignments are going to be described (by us) and completed (by you) using the same Google Colab reference template script.\n",
        "* Google Colab offers a Python environment that can be accessed in your browser and executed using Google Cloud, so no local installation is necessary. It makes the setting-up process significantly easier! Please read [this quick tutorial](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb) notebook on Google Colab/Python.\n",
        "\n",
        "### 1.3 **Creating your Google Colab submission file**\n",
        "\n",
        "* Modify this template with your solutions to the assignment. You will find \"**TO-DO**\" indicators throughout the assingment highlighting portions of the code you are asked to complete.\n",
        "* Only edit the provided demplates in the bounds of the START TODO and END TODO flags.\n",
        "* Colab notebooks are divided into individual cells. You can execute the code inside of a given cell by pressing **CTRL+ENTER**, or that of all cells by pressing **CTRL+F9**. Variables must be \"executed\" in a cell before being used by subsequent ones (the same goes for libraries imported). Note that some cells of this assignment contain flags that must by changed (and executed) before you move forward.\n",
        "* If you completed the whole assignment, make sure that simply pressing \"**CTRL+F9**\" executes all cells correctly. **This is going to be the first marking step we will execute when evaluating your submission**.  \n",
        "\n",
        "### 1.4 **Use of open source code**\n",
        "\n",
        "* The use of small segments of freely-available code is permitted. However, it is **extremely important** that you indicate in your in-code comments where these are used, as well as their sources. Failure to do so can be considered plagiarism, which is a serious offence. Learn more about detection mechanisms and consequences of plagiarism at UVic [here](https://www.uvic.ca/library/research/citation/plagiarism/). Note that the programming assignments are designed so that most of their content should be created by you.     \n",
        "* You can never include too many of these only too few.\n",
        "* A number of functions/algorithms are already implemented by libraries we will use (e.g., [OpenCV](https://opencv.org/), [scikit-learn](https://scikit-learn.org/stable/)), however you should not use them unless otherwise instructed to do so. Mannualy coding some of these function is an important part of the learning process.  \n",
        "\n",
        "### 1.5 **Use of LLMs**\n",
        "* Use of LLMs is not permitted on any assignments in this course\n",
        "* Checks for plagarism of any for will be made at any time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YQS1k9BUa_8Z"
      },
      "outputs": [],
      "source": [
        "READ_THE_INSTRUCTIONS_FLAG = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab-6ULjWQ4o1"
      },
      "source": [
        "## **2. Mathematical and Theoretical Questions  (23 points)**\n",
        "\n",
        "#### Answer all these questions in a seperate pdf!\n",
        "\n",
        "### **2.1 Linear Algebra**\n",
        "\n",
        "Consider the following vectors and matrix to answer the questions. **If you believe that a particular question has no answer, justify why**. Your work should be reported in the *.pdf* document included in the submission package.\n",
        "\n",
        "$v$ = \\begin{bmatrix}\n",
        "    3 & 2 & 1\n",
        "    \\end{bmatrix}\n",
        "\n",
        "$B$ = \\begin{bmatrix}\n",
        "    2 & 1 & 0 \\\\\n",
        "    4 & 3 & 0 \\\\\n",
        "    6 & 5 & 0\n",
        "    \\end{bmatrix}\n",
        "\n",
        "$A$ = \\begin{bmatrix}\n",
        "    0 & 2 & 3 \\\\\n",
        "    1 & 2 & 1 \\\\\n",
        "    1 & 0 & -1\n",
        "    \\end{bmatrix}   \n",
        "\n",
        "* 2.1.a) $v + 1$ (1 point)\n",
        "* 2.1.b) $v + v^{T}$ (1 point)\n",
        "* 2.1.c) $v \\cdot v^T$ (dot product) (2 points)\n",
        "* 2.1.d) $v \\times B$ (cross product). Consider that each column in $B$ represents an individual vector. You can follow that same consideration when writing your answer (i.e., as a matrix) (4 points)\n",
        "* 2.1.e) $v \\bullet B$ (matrix multiplication) (2 points)\n",
        "* 2.1.f) Calculate the eigenvalues of $A$ (10 points)\n",
        "* 2.1.g) Give one example of a property of the data that eigenvalues/eigenvectors represent (i.e., why is calculating the eigenvalues/eigenvectors useful)? (3 marks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRhMh6tJjvcc"
      },
      "source": [
        "# **3. Programming: introduction to Python, Colab and OpenCV (72 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4ecEgtjzOY"
      },
      "source": [
        "### **3.1 Basic image operations** (27 points)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In the first part of this programming assignment, you will load, transform, display and save an input image. (5 Points)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "b_yOTMF-S_e-",
        "outputId": "d91843a7-0609-4327-89f4-73861dd9610c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Python version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "OpenCV version: 4.10.0\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "Please go back and read the instructions.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6425de038caa>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREAD_THE_INSTRUCTIONS_FLAG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please go back and read the instructions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nThank you for reading the instructions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Please go back and read the instructions."
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import cv2 # imports OpenCV\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt #imports matplotlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n",
        "\n",
        "print('-'*40)\n",
        "print ('Python version: {}'.format(sys.version))\n",
        "print('OpenCV version: {}'.format(cv2.__version__))\n",
        "\n",
        "if not READ_THE_INSTRUCTIONS_FLAG:\n",
        "  raise Exception('Please go back and read the instructions.')\n",
        "else:\n",
        "  print('\\nThank you for reading the instructions.')\n",
        "print('-'*40)\n",
        "\n",
        "input_address = \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/uvic_1.jpg\"\n",
        "\n",
        "# TO-DO (3 points): download the input image from \"input_address\" using \"wget\" as a terminal command using the !<command> <aguments>. This download should only happen if there\n",
        "# are no files called \"uvic_1.jpg\" in your working directory (i.e., create a conditional to check for that).\n",
        "\n",
        "\n",
        "# END TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wICDEiOuI1l"
      },
      "outputs": [],
      "source": [
        "#TO-DO (2 points): use OpenCV (i.e., cv2) to store the image in a variable called \"img\"\n",
        "# and print its dimensions and number of channels.\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "# TO-DO (2 points): use OpenCV to reduce the dimension of the image in 65%. Print\n",
        "# its dimensions once again afterwards.\n",
        "\n",
        "\n",
        "\n",
        "# END TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dHyzfOaROGZ"
      },
      "source": [
        "**Plotting the image**: given that colab does not support OpenCV's \"imshow\", we will use matplotlib plotting functions (i.e., plt). [This](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.00-Introduction-To-Matplotlib.ipynb) is a great series of notebooks describing the use of matplotlib in Google Colab. (5 Points)\n",
        "\n",
        "Tips: plots from matplotlib are automatically scaled and might seem small at times. You can configure their sizes using **plt.figure(figsize = (a,b))** before creating a plot object. Note that a and b reflect, by default, inches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JAX3dONRNRv"
      },
      "outputs": [],
      "source": [
        "# TO-DO (1 point):\n",
        "# Convert the img from the colorspace BGR to RGB, as OpenCV read it as BGR and matplotlib requires RGB.\n",
        "# Then create a 1 channel image variable name <green_channel> which consists of only the green channel of <img>.\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "def pltImg(img, title=None, ori=\"horizontal\", colorb = True):\n",
        "  plt.imshow(img)\n",
        "  if colorb:\n",
        "    plt.colorbar(orientation=ori)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  return plt\n",
        "\n",
        "plt.figure(figsize = (15,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(img,title=\"Original color image\", ori='vertical')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(green_channel,title = \"Green color channel\", ori='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87hMaXZDSAho"
      },
      "source": [
        "**Rescalling the image**: you will often work with image files in different ranges. Typical ranges include (but are not limited to) [0,1] and [0,255]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVLMLqSO039A"
      },
      "outputs": [],
      "source": [
        "# TO-DO (2 points): rescale the image to the [0,1] range. Print the max and min values of the rescaled image and\n",
        "# plot the new color image.\n",
        "\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "imgInfo(rescaled, title = \"Rescaled\")\n",
        "plt.figure(figsize = (12,5))\n",
        "pltImg(rescaled,title=\"Rescaled to [0,1]\", ori='vertical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqlHHUUcKkla"
      },
      "outputs": [],
      "source": [
        "def turnGrey(img, threeD=True):\n",
        "# TO-DO (5 points):\n",
        "# 1) Create a greyscale version of the color image MANUALLY;\n",
        "# 2) Plot this greyscale image.\n",
        "# - Use the function template provided.\n",
        "# If threeD is true return a (h,w,3) array otherwise return a (h,w) array\n",
        "\n",
        "  return grey\n",
        "\n",
        "# END TODO\n",
        "greyImg = turnGrey(rescaled)\n",
        "imgInfo(greyImg, title='greyscale image')\n",
        "plt.figure(figsize = (12,12))\n",
        "pltImg(greyImg, title='Greyscale image', colorb=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsc05nykJGVB"
      },
      "source": [
        "**Point operators**: these common operators will consider a single pixel intensity of the input image when calculating a given output intensity (conversely from neighborhood operators such as image filters).   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWWEDOyxCvn2"
      },
      "outputs": [],
      "source": [
        "# TO-DO (4 points): Create two modified versions of the rescaled image.\n",
        "# 1) Brigthen the image by adding scalar 0.3 to all its pixel intensities;\n",
        "# 2) Darken the image by subtracting all pixel values by scalar 0.3.\n",
        "# Note 1: your input image should have pixel intensities inside range [0,1].\n",
        "# Note 2: The pixel intensities of the modified image should be inside range [0,1] (i.e., clip intensities if necessary).\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "plt.figure(figsize = (14,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(brighter,title=\"Brigther image\", ori='vertical')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(darker,title = \"Darker image\", ori='vertical')\n",
        "plt.subplots_adjust(wspace=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T1Xr9mcJkVN"
      },
      "outputs": [],
      "source": [
        "def pltImg(img, title=None, ori=\"horizontal\", colorb = True):  # not mandatory, but useful\n",
        "  plt.imshow(img)\n",
        "  if colorb:\n",
        "    plt.colorbar(orientation=ori)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  return plt\n",
        "\n",
        "gamma_original_address = \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/gamma_original.jpg\"\n",
        "\n",
        "# TO-DO (5 points): Perform gamma correction in the image located at \"gamma_original_address\".\n",
        "# 1. Download the original image (check if it has been already downloaded first).\n",
        "# 2. Perform gamma correction with gamma = 2.2 (refer to gamma correction slides from Lecture #3).\n",
        "# 3. Plot the original and corrected images in the same plot using matplotlib.\n",
        "\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "plt.figure(figsize = (14,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt = pltImg(gamma_img,title=\"Original image\", colorb=False)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt = pltImg(gamma_corrected,title = \"Gamma corrected image\", colorb=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD4YuUu4wLyn"
      },
      "outputs": [],
      "source": [
        "# # TO-DO (3 points): Save all modified images (i.e., brigther, darker and greyscale) in your Colab working directory\n",
        "# with .jpg extensions using OpenCV's \"cv2.imwrite\". The images should be saved\n",
        "# in a folder named \"output\" (create this folder USING PYTHON if it does not yet exist).\n",
        "# Tips: use \"cv2.normalize\". Be careful with the image ranges and types. The\n",
        "# saved images should preserve the \"brighter\", \"darker\" and \"grey\" effects.\n",
        "\n",
        "\n",
        "\n",
        "# END TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHfrcvQMQngJ"
      },
      "source": [
        "### **3.2 Histogram calculation and matching** (45 points)\n",
        "\n",
        "As discussed in class, histogram matching approximates a given pixel intensity frequency distribution (i.e., histogram) to a second, reference one. In this part of the assignment you are asked to create a function to implement such algorithm. See notes from the Point Operators and Histogram discussion (i.e., Lecture #3) for details on the Histogram matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2brFjpeDQdtW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def myHistogram(I, cumulative=True):\n",
        "# TO-DO (13 points): Implement a function that calculates the histogram and the cumulative histogram of a given image MANUALLY.\n",
        "# You CANNOT use any automated functions for histogram calculation (e.g., matplotlib.plt.hist, np.histogram, cv2.createCLAHE,\n",
        "# cv2.calcHist). Use the function template provided by filling it with your code.\n",
        "\n",
        "  return None\n",
        "# END TODO\n",
        "\n",
        "\n",
        "low_contrast_address = \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/low_contrast.jpg\"\n",
        "\n",
        "if os.path.isfile('./low_contrast.jpg'):\n",
        "  print('Low-contrast image file already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/low_contrast.jpg\"\n",
        "\n",
        "# reads the image and calculates the histograms\n",
        "lowc = cv2.imread('./low_contrast.jpg', 0)\n",
        "imgInfo(lowc, title=\"greyscale low-contrast image\")\n",
        "hist = myHistogram(lowc, cumulative=False)\n",
        "cumulative_hist = myHistogram(lowc)\n",
        "\n",
        "\n",
        "# plots the histograms\n",
        "plt.figure(figsize = (12,7))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.bar(np.arange(256),hist)\n",
        "plt.title('Histogram')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(np.arange(256),cumulative_hist)\n",
        "plt.title('Cumulative histogram')\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft_4Ny3jGkD7"
      },
      "outputs": [],
      "source": [
        "def match_histogram(I, Href, nref, debug=False):\n",
        "# TO-DO (12 points): Create a \"match_histogram\" function to implement the histogram matching algorithm. This function\n",
        "# receives an image, a reference cumulative histogram (previously calculated) and a reference number (you\n",
        "# can use the maximum value of the reference cumulative histogram as a default for this parameter). Its output is a\n",
        "# transformation function F(x) that will map an input pixel intensity to an output pixel intensity. For example,\n",
        "# if F[11]=17, an input pixel with intensity 11 should be replaced by one of intensity 17. See the details of the\n",
        "# algorithm in the Histogram lecture, available on BrightSpace. Use the function skeleton provided. (5 points)\n",
        "\n",
        "  return None\n",
        "# END TODO\n",
        "\n",
        "# TO-DO (2 points): Create a numpy array called Href with 256 positions populated with values 0,1,2,...,255.\n",
        "\n",
        "# END TODO\n",
        "\n",
        "# TO-DO (2 points): Calculate the cumulative histogram of Href using your myHistogram function. This is\n",
        "# going to represent your reference cumulative histogram.\n",
        "\n",
        "# END TODO\n",
        "\n",
        "\n",
        "\n",
        "# TO-DO (2 points): Use your \"match_histogram\" function where I is the low contrast image and Href is the\n",
        "# cumulative histogram you just calculated. You will obtain transformation function F.\n",
        "\n",
        "# END TODO\n",
        "\n",
        "\n",
        "# TO-DO (2 points): Apply F (the transformation function you just calculated) to transform\n",
        "# the pixel intensities from the original image to that of the histogram-matched\n",
        "# one. You should obtain the histogram-matched image as a result of this operation.\n",
        "\n",
        "# END TODO\n",
        "\n",
        "# TO-DO (3 points): Create a 4-element subplot with the matplot lib: 1) Original image; 2) Original\n",
        "# image's histogram; 3) Output image (result of the histogram matching procedure);\n",
        "# 4) the histogram of the output image.\n",
        "# Your output show look like this reference:\n",
        "# \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/reference_output_1.jpg\"\n",
        "# Tip 1: use \"plt.subplots_adjust\" to avoid overlapping between adjacent subplots.\n",
        "# Tip 2: make sure your images are 3-channel before trying to display them with\n",
        "# matplotlib.\n",
        "\n",
        "\n",
        "# END TODO\n",
        "\n",
        "\n",
        "plt.figure(figsize = (9,9))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.bar(np.arange(256),hist)\n",
        "plt.title('Original histogram')\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(lowc_plot)\n",
        "plt.title('Original image')\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.bar(np.arange(256),out_hist)\n",
        "plt.title('Output image histogram')\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.imshow(final_plot)\n",
        "plt.title('Output image')\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxl0JwuGjxi6"
      },
      "outputs": [],
      "source": [
        "# [Debug only]: the two cumulative histograms, although representing images with\n",
        "# different number of pixels (>35,000 for the input, 256 for the reference),\n",
        "# should present a similar shape after the matching\n",
        "\n",
        "out_cumulative = myHistogram(histogram_matched,cumulative=True)\n",
        "plt.figure(figsize = (9,9))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Matched cumulative histogram')\n",
        "plt.bar(np.arange(256),out_cumulative)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Reference cumulative histogram')\n",
        "plt.bar(np.arange(256),Href)\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4ey3e0W5G0V"
      },
      "outputs": [],
      "source": [
        "def matchRGB(target, reference):\n",
        "    # TO-DO (9 points): Adapt the histogram matching procedure to 3-channel images\n",
        "    # (i.e., a single histogram matching process done three times).\n",
        "    # Use the color image to calculate the refence cumulative histograms,\n",
        "    # and the B&W image as a target of the\n",
        "    # histogram matching process. Note that both images are 3-channel.\n",
        "\n",
        "\n",
        "    # END TO-DO\n",
        "    return targetFinal\n",
        "\n",
        "bw_target_add = \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/bw_target.jpg\"\n",
        "color_reference_add = \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/color_reference.jpg\"\n",
        "\n",
        "# (Download the images at \"bw_target_add\" and \"color_reference_add\") and\n",
        "# use them as input of your matchRGB function\n",
        "\n",
        "# download B&W target image\n",
        "if os.path.isfile('./bw_target.jpg'):\n",
        "  print('B&W target image already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/bw_target.jpg\"\n",
        "#!rm './color_reference.png'\n",
        "# download color reference image\n",
        "if os.path.isfile('./color_reference.png'):\n",
        "  print('Color reference image already downloaded.')\n",
        "else:\n",
        "  !wget \"https://raw.githubusercontent.com/dash-uvic/ece471_536-S2022/main/images/A1/color_reference.jpg\"\n",
        "\n",
        "colorRef = cv2.imread('./color_reference.jpg')\n",
        "bwImg = cv2.imread('./bw_target.jpg')\n",
        "h, w = colorRef.shape[:2]\n",
        "final = matchRGB(bwImg,colorRef)\n",
        "\n",
        "plt.figure(figsize = (9,9))\n",
        "plt.subplot(2,1,1)\n",
        "pltImg(cv2.cvtColor(colorRef,cv2.COLOR_BGR2RGB),title=\"Color reference\",colorb=False)\n",
        "plt.subplot(2,1,2)\n",
        "pltImg(cv2.cvtColor(final,cv2.COLOR_BGR2RGB),title=\"Output image\",colorb=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENSjUV3ATDm9"
      },
      "source": [
        "**End of the assignment!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
